{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Fine-Tunning du modèle Resnet101\n"
      ],
      "metadata": {
        "id": "X9QcZcjYUJen"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrwuxqhTqy4E",
        "outputId": "26431b51-8f4c-4755-eb5e-0a8144da50d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Mettre les images en RGB"
      ],
      "metadata": {
        "id": "fibeKM5qUbiO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "# Spécifiez le chemin de votre dossier d'images\n",
        "dossier_images = \"/content/drive/MyDrive/Projet_Vision/image_vision/random/val/0\"\n",
        "dossier_images2 = \"/content/drive/MyDrive/Projet_Vision/image/val/0\"\n",
        "\n",
        "# Obtenez la liste de tous les fichiers dans le dossier\n",
        "liste_fichiers = os.listdir(dossier_images)\n",
        "\n",
        "# Boucle à travers tous les fichiers du dossier\n",
        "for nom_fichier in liste_fichiers:\n",
        "    chemin_image = os.path.join(dossier_images, nom_fichier)\n",
        "\n",
        "    # Vérifiez si le fichier est une image (vous pouvez ajuster les extensions selon vos besoins)\n",
        "    if nom_fichier.lower().endswith(('.png', '.jpg', '.jpeg', '.gif')):\n",
        "        # Chargez l'image en niveau de gris (L)\n",
        "        image_en_rgb = Image.open(chemin_image).convert(\"RGB\")\n",
        "\n",
        "        # Enregistrez ou affichez l'image en RGB selon vos besoins\n",
        "        # Par exemple, pour enregistrer l'image :\n",
        "        chemin_image_en_rgb = os.path.join(dossier_images2, \"RGB_\" + nom_fichier)\n",
        "        image_en_rgb.save(chemin_image_en_rgb)\n"
      ],
      "metadata": {
        "id": "m2lmAeqeq0fb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Traitement des images"
      ],
      "metadata": {
        "id": "xLnxs0p1UyoP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EgtW2rQBqXl6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import datasets, models, transforms\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "\n",
        "data_transforms = {\n",
        "    'train':\n",
        "    transforms.Compose([\n",
        "        transforms.Resize((224,224)),\n",
        "        transforms.ToTensor(),\n",
        "        normalize\n",
        "    ]),\n",
        "    'validation':\n",
        "    transforms.Compose([\n",
        "        transforms.Resize((224,224)),\n",
        "        transforms.ToTensor(),\n",
        "        normalize\n",
        "    ])\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Affectation des différents dataset à leur dataloader respectives"
      ],
      "metadata": {
        "id": "O9y4edhhU2S-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_datasets = {\n",
        "    'train':\n",
        "    datasets.ImageFolder(\"/content/drive/MyDrive/Projet_Vision/image/train\", data_transforms['train']),\n",
        "    'validation':\n",
        "    datasets.ImageFolder('/content/drive/MyDrive/Projet_Vision/image/val', data_transforms['validation']),\n",
        "    'test':\n",
        "    datasets.ImageFolder('/content/drive/MyDrive/Projet_Vision/image/test', data_transforms['validation'])\n",
        "}\n",
        "\n",
        "dataloaders = {\n",
        "    'train':\n",
        "    torch.utils.data.DataLoader(image_datasets['train'],\n",
        "                                batch_size=32,\n",
        "                                shuffle=True,\n",
        "                                num_workers=0),\n",
        "    'validation':\n",
        "    torch.utils.data.DataLoader(image_datasets['validation'],\n",
        "                                batch_size=32,\n",
        "                                shuffle=False,\n",
        "                                num_workers=0),\n",
        "    'test':\n",
        "    torch.utils.data.DataLoader(image_datasets['test'],\n",
        "                                batch_size=32,\n",
        "                                shuffle=False,\n",
        "                                num_workers=0)\n",
        "}"
      ],
      "metadata": {
        "id": "Dbc3WokEqcoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloaders[\"train\"].dataset\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0L6oqgXqcy1",
        "outputId": "33c93d26-581f-4eb8-9b18-4a6989cccf53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset ImageFolder\n",
              "    Number of datapoints: 1600\n",
              "    Root location: /content/drive/MyDrive/Projet_Vision/image/train\n",
              "    StandardTransform\n",
              "Transform: Compose(\n",
              "               Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=warn)\n",
              "               ToTensor()\n",
              "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
              "           )"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "jYYfyP11qc2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6XUipKkIgrp",
        "outputId": "125a1945-1d03-40dc-a17b-34ce97a0202f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Fine-Tunning du modèle et initialisation du modèle"
      ],
      "metadata": {
        "id": "gwwDTwbQVBlO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet101(weights = models.ResNet101_Weights.DEFAULT).to(device)\n",
        "\n",
        "# Freeze all parameters by default\n",
        "for param in model.parameters():\n",
        "  param.requires_grad = True\n",
        "\n",
        "# Specify layers to be trained\n",
        "#layer1 = \"layer4\"\n",
        "layer2 = \"layer3\"\n",
        "layer3 = \"layer2\"\n",
        "layer4 = \"layer1\"\n",
        "for name, param in model.named_parameters():\n",
        "  #if layer1 in name:\n",
        "    #param.requires_grad = True\n",
        "  if layer2 in name:\n",
        "    param.requires_grad = False\n",
        "  if layer3 in name:\n",
        "    param.requires_grad = False\n",
        "  if layer4 in name:\n",
        "    param.requires_grad = False\n",
        "  print(name, param.requires_grad)\n",
        "\n",
        "model.fc = nn.Sequential(\n",
        "               nn.Linear(2048, 128),\n",
        "               nn.ReLU(inplace=True),\n",
        "               nn.Linear(128, 2)).to(device)"
      ],
      "metadata": {
        "id": "hJQCxyf4qc5l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2298d63a-0ab6-482c-f587-a85e34238a5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet101-cd907fc2.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-cd907fc2.pth\n",
            "100%|██████████| 171M/171M [00:01<00:00, 154MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv1.weight True\n",
            "bn1.weight True\n",
            "bn1.bias True\n",
            "layer1.0.conv1.weight False\n",
            "layer1.0.bn1.weight False\n",
            "layer1.0.bn1.bias False\n",
            "layer1.0.conv2.weight False\n",
            "layer1.0.bn2.weight False\n",
            "layer1.0.bn2.bias False\n",
            "layer1.0.conv3.weight False\n",
            "layer1.0.bn3.weight False\n",
            "layer1.0.bn3.bias False\n",
            "layer1.0.downsample.0.weight False\n",
            "layer1.0.downsample.1.weight False\n",
            "layer1.0.downsample.1.bias False\n",
            "layer1.1.conv1.weight False\n",
            "layer1.1.bn1.weight False\n",
            "layer1.1.bn1.bias False\n",
            "layer1.1.conv2.weight False\n",
            "layer1.1.bn2.weight False\n",
            "layer1.1.bn2.bias False\n",
            "layer1.1.conv3.weight False\n",
            "layer1.1.bn3.weight False\n",
            "layer1.1.bn3.bias False\n",
            "layer1.2.conv1.weight False\n",
            "layer1.2.bn1.weight False\n",
            "layer1.2.bn1.bias False\n",
            "layer1.2.conv2.weight False\n",
            "layer1.2.bn2.weight False\n",
            "layer1.2.bn2.bias False\n",
            "layer1.2.conv3.weight False\n",
            "layer1.2.bn3.weight False\n",
            "layer1.2.bn3.bias False\n",
            "layer2.0.conv1.weight False\n",
            "layer2.0.bn1.weight False\n",
            "layer2.0.bn1.bias False\n",
            "layer2.0.conv2.weight False\n",
            "layer2.0.bn2.weight False\n",
            "layer2.0.bn2.bias False\n",
            "layer2.0.conv3.weight False\n",
            "layer2.0.bn3.weight False\n",
            "layer2.0.bn3.bias False\n",
            "layer2.0.downsample.0.weight False\n",
            "layer2.0.downsample.1.weight False\n",
            "layer2.0.downsample.1.bias False\n",
            "layer2.1.conv1.weight False\n",
            "layer2.1.bn1.weight False\n",
            "layer2.1.bn1.bias False\n",
            "layer2.1.conv2.weight False\n",
            "layer2.1.bn2.weight False\n",
            "layer2.1.bn2.bias False\n",
            "layer2.1.conv3.weight False\n",
            "layer2.1.bn3.weight False\n",
            "layer2.1.bn3.bias False\n",
            "layer2.2.conv1.weight False\n",
            "layer2.2.bn1.weight False\n",
            "layer2.2.bn1.bias False\n",
            "layer2.2.conv2.weight False\n",
            "layer2.2.bn2.weight False\n",
            "layer2.2.bn2.bias False\n",
            "layer2.2.conv3.weight False\n",
            "layer2.2.bn3.weight False\n",
            "layer2.2.bn3.bias False\n",
            "layer2.3.conv1.weight False\n",
            "layer2.3.bn1.weight False\n",
            "layer2.3.bn1.bias False\n",
            "layer2.3.conv2.weight False\n",
            "layer2.3.bn2.weight False\n",
            "layer2.3.bn2.bias False\n",
            "layer2.3.conv3.weight False\n",
            "layer2.3.bn3.weight False\n",
            "layer2.3.bn3.bias False\n",
            "layer3.0.conv1.weight False\n",
            "layer3.0.bn1.weight False\n",
            "layer3.0.bn1.bias False\n",
            "layer3.0.conv2.weight False\n",
            "layer3.0.bn2.weight False\n",
            "layer3.0.bn2.bias False\n",
            "layer3.0.conv3.weight False\n",
            "layer3.0.bn3.weight False\n",
            "layer3.0.bn3.bias False\n",
            "layer3.0.downsample.0.weight False\n",
            "layer3.0.downsample.1.weight False\n",
            "layer3.0.downsample.1.bias False\n",
            "layer3.1.conv1.weight False\n",
            "layer3.1.bn1.weight False\n",
            "layer3.1.bn1.bias False\n",
            "layer3.1.conv2.weight False\n",
            "layer3.1.bn2.weight False\n",
            "layer3.1.bn2.bias False\n",
            "layer3.1.conv3.weight False\n",
            "layer3.1.bn3.weight False\n",
            "layer3.1.bn3.bias False\n",
            "layer3.2.conv1.weight False\n",
            "layer3.2.bn1.weight False\n",
            "layer3.2.bn1.bias False\n",
            "layer3.2.conv2.weight False\n",
            "layer3.2.bn2.weight False\n",
            "layer3.2.bn2.bias False\n",
            "layer3.2.conv3.weight False\n",
            "layer3.2.bn3.weight False\n",
            "layer3.2.bn3.bias False\n",
            "layer3.3.conv1.weight False\n",
            "layer3.3.bn1.weight False\n",
            "layer3.3.bn1.bias False\n",
            "layer3.3.conv2.weight False\n",
            "layer3.3.bn2.weight False\n",
            "layer3.3.bn2.bias False\n",
            "layer3.3.conv3.weight False\n",
            "layer3.3.bn3.weight False\n",
            "layer3.3.bn3.bias False\n",
            "layer3.4.conv1.weight False\n",
            "layer3.4.bn1.weight False\n",
            "layer3.4.bn1.bias False\n",
            "layer3.4.conv2.weight False\n",
            "layer3.4.bn2.weight False\n",
            "layer3.4.bn2.bias False\n",
            "layer3.4.conv3.weight False\n",
            "layer3.4.bn3.weight False\n",
            "layer3.4.bn3.bias False\n",
            "layer3.5.conv1.weight False\n",
            "layer3.5.bn1.weight False\n",
            "layer3.5.bn1.bias False\n",
            "layer3.5.conv2.weight False\n",
            "layer3.5.bn2.weight False\n",
            "layer3.5.bn2.bias False\n",
            "layer3.5.conv3.weight False\n",
            "layer3.5.bn3.weight False\n",
            "layer3.5.bn3.bias False\n",
            "layer3.6.conv1.weight False\n",
            "layer3.6.bn1.weight False\n",
            "layer3.6.bn1.bias False\n",
            "layer3.6.conv2.weight False\n",
            "layer3.6.bn2.weight False\n",
            "layer3.6.bn2.bias False\n",
            "layer3.6.conv3.weight False\n",
            "layer3.6.bn3.weight False\n",
            "layer3.6.bn3.bias False\n",
            "layer3.7.conv1.weight False\n",
            "layer3.7.bn1.weight False\n",
            "layer3.7.bn1.bias False\n",
            "layer3.7.conv2.weight False\n",
            "layer3.7.bn2.weight False\n",
            "layer3.7.bn2.bias False\n",
            "layer3.7.conv3.weight False\n",
            "layer3.7.bn3.weight False\n",
            "layer3.7.bn3.bias False\n",
            "layer3.8.conv1.weight False\n",
            "layer3.8.bn1.weight False\n",
            "layer3.8.bn1.bias False\n",
            "layer3.8.conv2.weight False\n",
            "layer3.8.bn2.weight False\n",
            "layer3.8.bn2.bias False\n",
            "layer3.8.conv3.weight False\n",
            "layer3.8.bn3.weight False\n",
            "layer3.8.bn3.bias False\n",
            "layer3.9.conv1.weight False\n",
            "layer3.9.bn1.weight False\n",
            "layer3.9.bn1.bias False\n",
            "layer3.9.conv2.weight False\n",
            "layer3.9.bn2.weight False\n",
            "layer3.9.bn2.bias False\n",
            "layer3.9.conv3.weight False\n",
            "layer3.9.bn3.weight False\n",
            "layer3.9.bn3.bias False\n",
            "layer3.10.conv1.weight False\n",
            "layer3.10.bn1.weight False\n",
            "layer3.10.bn1.bias False\n",
            "layer3.10.conv2.weight False\n",
            "layer3.10.bn2.weight False\n",
            "layer3.10.bn2.bias False\n",
            "layer3.10.conv3.weight False\n",
            "layer3.10.bn3.weight False\n",
            "layer3.10.bn3.bias False\n",
            "layer3.11.conv1.weight False\n",
            "layer3.11.bn1.weight False\n",
            "layer3.11.bn1.bias False\n",
            "layer3.11.conv2.weight False\n",
            "layer3.11.bn2.weight False\n",
            "layer3.11.bn2.bias False\n",
            "layer3.11.conv3.weight False\n",
            "layer3.11.bn3.weight False\n",
            "layer3.11.bn3.bias False\n",
            "layer3.12.conv1.weight False\n",
            "layer3.12.bn1.weight False\n",
            "layer3.12.bn1.bias False\n",
            "layer3.12.conv2.weight False\n",
            "layer3.12.bn2.weight False\n",
            "layer3.12.bn2.bias False\n",
            "layer3.12.conv3.weight False\n",
            "layer3.12.bn3.weight False\n",
            "layer3.12.bn3.bias False\n",
            "layer3.13.conv1.weight False\n",
            "layer3.13.bn1.weight False\n",
            "layer3.13.bn1.bias False\n",
            "layer3.13.conv2.weight False\n",
            "layer3.13.bn2.weight False\n",
            "layer3.13.bn2.bias False\n",
            "layer3.13.conv3.weight False\n",
            "layer3.13.bn3.weight False\n",
            "layer3.13.bn3.bias False\n",
            "layer3.14.conv1.weight False\n",
            "layer3.14.bn1.weight False\n",
            "layer3.14.bn1.bias False\n",
            "layer3.14.conv2.weight False\n",
            "layer3.14.bn2.weight False\n",
            "layer3.14.bn2.bias False\n",
            "layer3.14.conv3.weight False\n",
            "layer3.14.bn3.weight False\n",
            "layer3.14.bn3.bias False\n",
            "layer3.15.conv1.weight False\n",
            "layer3.15.bn1.weight False\n",
            "layer3.15.bn1.bias False\n",
            "layer3.15.conv2.weight False\n",
            "layer3.15.bn2.weight False\n",
            "layer3.15.bn2.bias False\n",
            "layer3.15.conv3.weight False\n",
            "layer3.15.bn3.weight False\n",
            "layer3.15.bn3.bias False\n",
            "layer3.16.conv1.weight False\n",
            "layer3.16.bn1.weight False\n",
            "layer3.16.bn1.bias False\n",
            "layer3.16.conv2.weight False\n",
            "layer3.16.bn2.weight False\n",
            "layer3.16.bn2.bias False\n",
            "layer3.16.conv3.weight False\n",
            "layer3.16.bn3.weight False\n",
            "layer3.16.bn3.bias False\n",
            "layer3.17.conv1.weight False\n",
            "layer3.17.bn1.weight False\n",
            "layer3.17.bn1.bias False\n",
            "layer3.17.conv2.weight False\n",
            "layer3.17.bn2.weight False\n",
            "layer3.17.bn2.bias False\n",
            "layer3.17.conv3.weight False\n",
            "layer3.17.bn3.weight False\n",
            "layer3.17.bn3.bias False\n",
            "layer3.18.conv1.weight False\n",
            "layer3.18.bn1.weight False\n",
            "layer3.18.bn1.bias False\n",
            "layer3.18.conv2.weight False\n",
            "layer3.18.bn2.weight False\n",
            "layer3.18.bn2.bias False\n",
            "layer3.18.conv3.weight False\n",
            "layer3.18.bn3.weight False\n",
            "layer3.18.bn3.bias False\n",
            "layer3.19.conv1.weight False\n",
            "layer3.19.bn1.weight False\n",
            "layer3.19.bn1.bias False\n",
            "layer3.19.conv2.weight False\n",
            "layer3.19.bn2.weight False\n",
            "layer3.19.bn2.bias False\n",
            "layer3.19.conv3.weight False\n",
            "layer3.19.bn3.weight False\n",
            "layer3.19.bn3.bias False\n",
            "layer3.20.conv1.weight False\n",
            "layer3.20.bn1.weight False\n",
            "layer3.20.bn1.bias False\n",
            "layer3.20.conv2.weight False\n",
            "layer3.20.bn2.weight False\n",
            "layer3.20.bn2.bias False\n",
            "layer3.20.conv3.weight False\n",
            "layer3.20.bn3.weight False\n",
            "layer3.20.bn3.bias False\n",
            "layer3.21.conv1.weight False\n",
            "layer3.21.bn1.weight False\n",
            "layer3.21.bn1.bias False\n",
            "layer3.21.conv2.weight False\n",
            "layer3.21.bn2.weight False\n",
            "layer3.21.bn2.bias False\n",
            "layer3.21.conv3.weight False\n",
            "layer3.21.bn3.weight False\n",
            "layer3.21.bn3.bias False\n",
            "layer3.22.conv1.weight False\n",
            "layer3.22.bn1.weight False\n",
            "layer3.22.bn1.bias False\n",
            "layer3.22.conv2.weight False\n",
            "layer3.22.bn2.weight False\n",
            "layer3.22.bn2.bias False\n",
            "layer3.22.conv3.weight False\n",
            "layer3.22.bn3.weight False\n",
            "layer3.22.bn3.bias False\n",
            "layer4.0.conv1.weight True\n",
            "layer4.0.bn1.weight True\n",
            "layer4.0.bn1.bias True\n",
            "layer4.0.conv2.weight True\n",
            "layer4.0.bn2.weight True\n",
            "layer4.0.bn2.bias True\n",
            "layer4.0.conv3.weight True\n",
            "layer4.0.bn3.weight True\n",
            "layer4.0.bn3.bias True\n",
            "layer4.0.downsample.0.weight True\n",
            "layer4.0.downsample.1.weight True\n",
            "layer4.0.downsample.1.bias True\n",
            "layer4.1.conv1.weight True\n",
            "layer4.1.bn1.weight True\n",
            "layer4.1.bn1.bias True\n",
            "layer4.1.conv2.weight True\n",
            "layer4.1.bn2.weight True\n",
            "layer4.1.bn2.bias True\n",
            "layer4.1.conv3.weight True\n",
            "layer4.1.bn3.weight True\n",
            "layer4.1.bn3.bias True\n",
            "layer4.2.conv1.weight True\n",
            "layer4.2.bn1.weight True\n",
            "layer4.2.bn1.bias True\n",
            "layer4.2.conv2.weight True\n",
            "layer4.2.bn2.weight True\n",
            "layer4.2.bn2.bias True\n",
            "layer4.2.conv3.weight True\n",
            "layer4.2.bn3.weight True\n",
            "layer4.2.bn3.bias True\n",
            "fc.weight True\n",
            "fc.bias True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Paramètre utilisé"
      ],
      "metadata": {
        "id": "gf4PJPHcVH3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(),lr=0.0001)"
      ],
      "metadata": {
        "id": "7Cz-91l3qc8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Fonction pour l'entrainement du modèle"
      ],
      "metadata": {
        "id": "K7dGw5OQVLgh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "\n",
        "def train_model(model, criterion, optimizer, num_epochs):\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    train_loss = []\n",
        "    val_loss = []\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
        "        print('-' * 10)\n",
        "\n",
        "        for phase in ['train', 'validation']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "            if phase == 'validation':\n",
        "              val_loss.append(epoch_loss)\n",
        "            if phase == 'train':\n",
        "              train_loss.append(epoch_loss)\n",
        "            # Deep copy the model if it has the best validation accuracy\n",
        "            if phase == 'validation' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    # Load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "\n",
        "    return model, val_loss, train_loss"
      ],
      "metadata": {
        "id": "hU2-IDfzqc_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_trained, val_loss, train_loss = train_model(model, criterion, optimizer, num_epochs=10)"
      ],
      "metadata": {
        "id": "Bgd5q8DeqdFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Affichage de la loss"
      ],
      "metadata": {
        "id": "_aAZaDv9VZES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = range(1, len(val_loss) + 1)\n",
        "\n",
        "# Plotting the loss values\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
        "plt.plot(epochs, train_loss, 'b', label='Training Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jL8M3xuEqdH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Calcul de l'accuracy ainsi que de la matrice de convolution pour l'ensemble de test"
      ],
      "metadata": {
        "id": "W1ujMRePVxlJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = model_trained\n"
      ],
      "metadata": {
        "id": "GzgTMAe4qdK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model_trained.state_dict(), '/content/drive/MyDrive/Projet_Vision/weights10.h5')"
      ],
      "metadata": {
        "id": "UW8Pvm4mqdNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet101(weights = models.ResNet101_Weights.DEFAULT).to(device)\n",
        "\n",
        "# Freeze all parameters by default\n",
        "for param in model.parameters():\n",
        "  param.requires_grad = True\n",
        "\n",
        "# Specify layers to be trained\n",
        "#layer1 = \"layer4\"\n",
        "layer2 = \"layer3\"\n",
        "layer3 = \"layer2\"\n",
        "layer4 = \"layer1\"\n",
        "for name, param in model.named_parameters():\n",
        "  #if layer1 in name:\n",
        "    #param.requires_grad = True\n",
        "  if layer2 in name:\n",
        "    param.requires_grad = False\n",
        "  if layer3 in name:\n",
        "    param.requires_grad = False\n",
        "  if layer4 in name:\n",
        "    param.requires_grad = False\n",
        "  print(name, param.requires_grad)\n",
        "\n",
        "model.fc = nn.Sequential(\n",
        "               nn.Linear(2048, 128),\n",
        "               nn.ReLU(inplace=True),\n",
        "               nn.Linear(128, 2)).to(device)\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/Projet_Vision/weights10.h5'))"
      ],
      "metadata": {
        "id": "EQyXCUq7qdQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "model.eval()\n",
        "\n",
        "# Define variables for keeping track of accuracy and total tested samples\n",
        "correct = 0\n",
        "total = 0\n",
        "true_labels = []\n",
        "predicted_labels = []\n",
        "\n",
        "class_1_counter = 0\n",
        "\n",
        "# Iterate through the test dataset\n",
        "for inputs, labels in dataloaders['test']:\n",
        "    inputs = inputs.to(device)  # Send inputs to device (GPU or CPU)\n",
        "    labels = labels.to(device)  # Send labels to device\n",
        "\n",
        "    # Forward pass\n",
        "    with torch.no_grad():  # No need to calculate gradients during inference\n",
        "        outputs = model(inputs)\n",
        "\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    print(predicted)\n",
        "\n",
        "    true_labels.extend(labels.cpu().numpy())\n",
        "    predicted_labels.extend(predicted.cpu().numpy())\n",
        "\n",
        "    # Calculate accuracy\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "# Calculate overall accuracy\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Accuracy on the test set: {accuracy:.2f}%')\n",
        "\n",
        "# Generate the confusion matrix\n",
        "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "# Print the confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "class_names = ['Class 0', 'Class 1']  # Replace with your actual class names\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Beo-Kbma6pAI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}